{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic calcium imaging analysis using Jupyter, Spark and Thunder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jupyter Notebook is an interactive web application for creating and sharing documents that contain live code, equations, visualizations and explanatory text. As a web application, it can be run simply within the browser while the underlying computations are either performed on the local computer, a remote server or even a remote cluster. Therefore, this approach to data analysis scales very well from small to large datasets: we can start by analysing a small part of our data set on the local machine and, once we are satisfied with the results, easily scale up to analyse the full data set on a cluster. The Jupyter notebook can also be used to share data and analysis with others. This can be useful e.g. for teaching or for providing data / analysis in the context of a publication. See for example [http://www.nature.com/news/ipython-interactive-demo-7.21492](http://www.nature.com/news/ipython-interactive-demo-7.21492) or [https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks#reproducible-academic-publications](https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks#reproducible-academic-publications).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os, sys\n",
    "import seaborn as sns\n",
    "\n",
    "# Set figure style options for Seaborn\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "# show figure in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add folder 'utils' to the Python path\n",
    "# this folder contains custom written code that is required for data import and analysis\n",
    "utils_dir = os.path.join(os.getcwd(), 'utils')\n",
    "sys.path.append(utils_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "layout": {
       "col": 0,
       "height": 4,
       "row": 0,
       "width": 4
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# starting Spark depends on where the notebook is running (local computer or OpenStack cluster)\n",
    "# choose 'local' or 'openstack'\n",
    "nbBackend = 'openstack'\n",
    "print \"Running notebook on \" + nbBackend + \" backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize Spark\n",
    "# returns the SparkContext object 'sc' which tells Spark how to access the cluster\n",
    "from setupSpark import initSpark\n",
    "sc = initSpark(nbBackend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add Python files in 'utils' folder to the SparkContext \n",
    "# this is required so that all files are available on all the cluster workers\n",
    "for filename in os.listdir(utils_dir):\n",
    "    if filename.endswith('.py'):\n",
    "        sc.addPyFile(os.path.join(utils_dir, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorial dataset consists of four example two-photon calcium imaging recordings performed by Frauke Leitner in the lab of Hannah Monyer at the DKFZ in Heidelberg. Recordings were obtained in the mouse lateral entorhinal cortex (LEC) while odor stimulation (6 different odors + air) was applied to the mouse nose. Calcium imaging was performed at ca. 5 Hz using standard frame scans. The calcium indicator is GCamp6, delivered by viral injection. Further details about the data set are described in the corresponding [paper](http://www.nature.com/neuro/journal/v19/n7/full/nn.4303.html).\n",
    "\n",
    "For the tutorial, raw data have already been background subtracted and Roi time series have been extracted and converted to DFF. The data are stored in HDF5 files, with one file per imaging area. For each trial, the file contains image data (2D matrix with different Rois' time series in separate rows), Roi coordinates, Roi names, a reference image of the population as well as stimulation information. Note that HDF5 files can be conveniently viewed using the free utility [HDFView](https://www.hdfgroup.org/products/java/hdfview/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# full path to directory containing HDF5 files\n",
    "directory = '/home/ubuntu/example_data/LEC_Data'\n",
    "\n",
    "# select HDF5 file\n",
    "# following files are available: \n",
    "# Monyer_Leitner_F296_spot01.h5\n",
    "# Monyer_Leitner_F397_spot01.h5\n",
    "# Monyer_Leitner_F400_spot02.h5\n",
    "# Monyer_Leitner_F400_spot04.h5\n",
    "h5file = 'Monyer_Leitner_F296_spot01.h5'\n",
    "h5file = directory + os.sep + h5file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# First, we obtain some information about the dataset (size, sampling rate, number of trials)\n",
    "# NeuroH5Utils is a python file in the 'utils' folder which contains functions for reading the HDF5 files\n",
    "from NeuroH5Utils import getFileInfo\n",
    "dsetSz, sampF, nTrials = getFileInfo(h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Next, we read the entire timeseries for one neuron to demonstrate the basic principle how data is read\n",
    "ix = 0 # Neuron index (zero-based in Python)\n",
    "from NeuroH5Utils import readPixel_map\n",
    "x, result = readPixel_map(ix, h5file, dim=1, debug=True) # debug=True will plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# We can also read the activity of all neurons at one timepoint by setting dim=2\n",
    "ix = 100\n",
    "from NeuroH5Utils import readPixel_map\n",
    "x, result = readPixel_map(ix, h5file, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Spark revolves around the concept of a resilient distributed dataset (RDD), which is a \n",
    "# collection of elements that can be operated on in parallel.\n",
    "# Thus, data has to be converted (parallelized) into an RDD\n",
    "# This is done with the function convert2RDD which calls readPixel_map on every neuron in the dataset\n",
    "from NeuroH5Utils import convert2RDD\n",
    "numPartitions = 10 # how many partitions?\n",
    "rdd = convert2RDD(sc, h5file, numPartitions=numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Spark uses 'lazy' execution, i.e. data is only accessed when its actually needed\n",
    "# We can use the count method to force loading of the data (this accesses every element once)\n",
    "# count returns number of elements in the RDD (i.e. dsetSz[0])\n",
    "nNeurons = rdd.count()\n",
    "nNeurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get time series from first roi to derive time axis and number of timepoints\n",
    "s  = np.asarray(rdd.lookup(0))\n",
    "t = (np.linspace(1, len(s[0]), len(s[0]))) / sampF \n",
    "nTimepoints = len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Finally, let's return a specific Roi as Python list / numpy array and plot the timeseries\n",
    "roi = 0\n",
    "s = rdd.lookup(roi) # returns a list\n",
    "s = np.asarray(s) # convert to np array (actually not required for plotting)\n",
    "plt.plot(t, s[0]);\n",
    "plt.xlim((0, np.max(t)));\n",
    "plt.xlabel('Time / s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Spark to Thunder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thunder is a collection of tools for the analysis of image and time series data in Python. It runs locally or against a Spark cluster. For more information on Thunder see [http://thunder-project.org/](http://thunder-project.org/) and the associated [paper](http://www.nature.com/nmeth/journal/v11/n9/full/nmeth.3041.html). \n",
    "The basic data types of Thunder are Images and Series objects. In the following, we will use the Series object to parallelize the timeseries from different neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# convert the Spark RDD into a Thunder Series object\n",
    "# this allows us to make use of the functions available for Series objects in the Thunder library\n",
    "import thunder as td\n",
    "# thunder fromrdd expects a key-value pair where the key is a tuple representing the index\n",
    "# here the keys are integers, so we wrap them in a single-element tuple\n",
    "series = td.series.fromrdd(rdd.map(lambda kv: ((kv[0],), kv[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Thunder provides a number of convenient functions for analyzing and processing the data\n",
    "# In this example, we filter the traces to select those with a mean intensity > 10% DFF. \n",
    "# Then, we select a subset of 5 traces and convert them to numpy arrays for plotting.\n",
    "# The example also demonstrates the use of lambda functions, a key technique in Python.\n",
    "examples = series.filter(lambda x: x.mean() > 10).sample(5).toarray()\n",
    "plt.plot(t, examples.T);\n",
    "plt.xlim((0, np.max(t)));\n",
    "plt.xlabel('Time / s');\n",
    "plt.ylabel('% DFF');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# In a similar way, compute the mean and standard deviation for each Roi\n",
    "series_mean = series.map(lambda x: x.mean()).flatten().toarray()\n",
    "series_sd = series.map(lambda x: x.std()).flatten().toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Scatter plot of Roi mean vs. SD\n",
    "plt.scatter(series_mean, series_sd)\n",
    "plt.xlabel('Roi Mean');\n",
    "plt.ylabel('Roi SD');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stimulation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, neural data is acquired in the presence of sensory stimulation or together with recording of behavioral data. For our example data set, odor stimulation (6 different odors + air) was applied to the mouse nose. Next, we import the stimulus data from the HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# import stimulus data\n",
    "# getStimData is a function defined in the NeuroH5Utils.py file\n",
    "from NeuroH5Utils import getStimData\n",
    "stimData, stimNames = getStimData(h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Now we can plot the timeseries for all neurons in stacked fashion and indicate the start of odor application\n",
    "# In principle, this could be done with both Thunder series objects and Spark RDDs\n",
    "# Based on non-comprehensive tests, it seems faster to extract data directly from Spark RDD\n",
    "fig = plt.figure(figsize=(8,4)) # increase figsize to (20,10) to improve visibility\n",
    "# loop over neurons to plot their respective timeseries\n",
    "offset = 0\n",
    "for iNeuron in range(nNeurons):\n",
    "    plotTrace = rdd.lookup(iNeuron) # returns a list\n",
    "    plotTrace = np.asarray(plotTrace) # convert to np array (actually not required for plotting)\n",
    "    plotTrace = plotTrace[0] - min(plotTrace[0]) + offset\n",
    "    offset = max(plotTrace)\n",
    "    plt.plot(t, plotTrace)\n",
    "# loop over stims and indicate them with vertical dashed lines\n",
    "for iTimepoint in range(len(stimData)):\n",
    "    if stimData[iTimepoint]:\n",
    "        tStim = t[iTimepoint]\n",
    "        plt.plot((tStim, tStim), (0, offset), 'k--')\n",
    "# some improvements to the default figure\n",
    "plt.xlabel('Time [s]', fontsize=18)\n",
    "plt.ylim((0, offset))\n",
    "plt.xlim((0, np.max(t)))\n",
    "ax = fig.gca()\n",
    "plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "plt.show()\n",
    "# save the figure if required\n",
    "# plt.savefig('Timeseries_AllStim.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The previous plot shows the 'raw' activity level in relation to odor stimulation\n",
    "# However, we might also be interested to know how the activity of a neuron changes on average for different odors\n",
    "# This can be done with the peri-stimulus plot - the average trace for each stimulus per neuron\n",
    "from CalciumAnalysisUtils import psAnalysis\n",
    "\n",
    "# select time interval to plot (in frames)\n",
    "baseFrames = 10\n",
    "evokedFrames = 100\n",
    "\n",
    "# compute peri-stimulus data for all neurons from the Spark RDD\n",
    "# this creates a new RDD called psData\n",
    "# rdd.map applies a function (in this case psAnalysis to all elements of the RDD in parallel)\n",
    "psData = rdd.map(lambda (k, v): (k, psAnalysis(v, stimData, (baseFrames, evokedFrames))))\n",
    "psData = psData.partitionBy(numPartitions).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# now create the plot\n",
    "\n",
    "# select Rois to plot\n",
    "roisToPlot = [2, 8, 12, 16, 19]\n",
    "# Or select all neurons\n",
    "# roisToPlot = range(nNeurons)\n",
    "\n",
    "fig = plt.figure(figsize=(20,20)) # (20, 200) for full dataset, otherwise fewer rows\n",
    "splotCounter = 1\n",
    "for ix, iRoi in enumerate(roisToPlot):\n",
    "    iRoi_data = np.asarray(psData.lookup(iRoi))\n",
    "    psDataByStim = iRoi_data[0]\n",
    "    # same y range for all stims\n",
    "    minY = min([ np.min(x) for x in psDataByStim ])\n",
    "    maxY = max([ np.max(x) for x in psDataByStim ])\n",
    "    # plot for each stimulus\n",
    "    for ix2, iStim in enumerate(psDataByStim):\n",
    "        meanData = np.mean(iStim,axis=0)\n",
    "        semData = np.std(iStim,axis=0) / np.sqrt(np.shape(iStim)[0])\n",
    "        tPs = (np.linspace(0, evokedFrames, meanData.size)-baseFrames)/sampF\n",
    "        plt.subplot(len(roisToPlot), len(psDataByStim), splotCounter)\n",
    "        splotCounter = splotCounter + 1\n",
    "        plt.fill_between(tPs, meanData-semData, meanData+semData, alpha=0.2)\n",
    "        plt.plot(tPs, meanData)\n",
    "        plt.plot((0,0), (minY, maxY), 'k--')\n",
    "        plt.xlim((min(tPs), max(tPs)))\n",
    "        plt.ylim((minY, maxY))\n",
    "        if ix == 0:\n",
    "            plt.title(stimNames[ix2+1])\n",
    "        if ix2 == 0:\n",
    "            plt.ylabel('%DFF Roi {0}'.format(iRoi+1))\n",
    "plt.show()\n",
    "# plt.savefig('PsPlot_AllStims.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display image of population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Finally, let's get the reference image for this population and display it\n",
    "from NeuroH5Utils import getReferenceImage\n",
    "from showit import image\n",
    "trial = 0 # specify trial (0 based indexing)\n",
    "refImage = getReferenceImage(h5file, trial=trial)\n",
    "image(refImage, clim=(0,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "urth": {
   "dashboard": {
    "cellMargin": 10,
    "defaultCellHeight": 20,
    "layout": "grid",
    "maxColumns": 12
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression analysis of calcium imaging data with the Spark Thunder library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass univariate regression is the process of independently regressing multiple response variables against a single set of explantory features. It is common in any domain in which a lage number of response variables are measured, and fitting large collections of such models can benefit significantly from parallelization. The following tutorial notebook describes how to perform a simple linear regression analysis with calcium imaging data to determine how different neurons' activity is modulated by sensory stimulation. The example data set is the same as the one used in [Tutorial_Basics](Tutorial_Basics.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup & data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is largely identical to the first part of [Tutorial_Basics](Tutorial_Basics.ipynb). To run it all in one go, you can select the next section heading ([Regression analysis](#regress)) and choose Cell --> Run All Above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import h5py\n",
    "import os, sys\n",
    "import seaborn as sns\n",
    "\n",
    "# Set figure style options for Seaborn\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "# show figure in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add folder 'utils' to the Python path\n",
    "# this folder contains custom written code that is required for data import and analysis\n",
    "utils_dir = os.path.join(os.getcwd(), 'utils')\n",
    "sys.path.append(utils_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "layout": {
       "col": 0,
       "height": 4,
       "row": 0,
       "width": 4
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# starting Spark depends on where the notebook is running (local computer or OpenStack cluster)\n",
    "# choose 'local' or 'openstack'\n",
    "nbBackend = 'openstack'\n",
    "print \"Running notebook on \" + nbBackend + \" backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize Spark\n",
    "# returns the SparkContext object 'sc' which tells Spark how to access the cluster\n",
    "from setupSpark import initSpark\n",
    "sc = initSpark(nbBackend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# add Python files in 'utils' folder to the SparkContext \n",
    "# this is required so that all files are available on all the cluster workers\n",
    "for filename in os.listdir(utils_dir):\n",
    "    if filename.endswith('.py'):\n",
    "        sc.addPyFile(os.path.join(utils_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# full path to directory containing HDF5 files\n",
    "directory = '/home/ubuntu/example_data/LEC_Data'\n",
    "\n",
    "# select HDF5 file\n",
    "# following files are available: \n",
    "# Monyer_Leitner_F296_spot01.h5\n",
    "# Monyer_Leitner_F397_spot01.h5\n",
    "# Monyer_Leitner_F400_spot02.h5\n",
    "# Monyer_Leitner_F400_spot04.h5\n",
    "h5file = 'Monyer_Leitner_F296_spot01.h5'\n",
    "h5file = directory + os.sep + h5file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# obtain further information about the dataset (size, sampling rate, number of trials)\n",
    "from NeuroH5Utils import getFileInfo\n",
    "dsetSz, sampF, nTrials = getFileInfo(h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# create the RDD and Thunder series\n",
    "import thunder as td\n",
    "from NeuroH5Utils import convert2RDD\n",
    "numPartitions = 10 # how many partitions?\n",
    "rdd = convert2RDD(sc, h5file, numPartitions=numPartitions)\n",
    "series = td.series.fromrdd(rdd.map(lambda kv: ((kv[0],), kv[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute number of neurons, time points and time axis\n",
    "nNeurons = series.count()\n",
    "nTimepoints = len(series.index)\n",
    "t = (np.linspace(1, nTimepoints, nTimepoints)) / sampF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# import stimulus data\n",
    "from NeuroH5Utils import getStimData\n",
    "stimData, stimNames = getStimData(h5file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "layout": {
       "col": 8,
       "height": 4,
       "row": 0,
       "width": 4
      }
     }
    }
   },
   "source": [
    "<a name=\"regress\"></a>\n",
    "### Regression analysis\n",
    "\n",
    "The following section demonstrates how to perform a mass univariate linear regression analysis of stimulus vector against the timeseries data for each ROI using Thunder. Regression is part of the Thunder analysis package thunder-regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, we need to build a design matrix from the stimulus vector. \n",
    "# The stimulus vector contains one value per time point, indicating the start of  a stimulus.\n",
    "# The design matrix should have one row per stimulus ID, indicating the onset of the respective stimulus. \n",
    "stimId = stimData[stimData>0].astype(np.int64) # need integer for indexing later\n",
    "stimIx = np.where(stimData>0)[0]\n",
    "nStims = len(np.unique(stimId))\n",
    "X = np.zeros((nStims, nTimepoints), int)\n",
    "for ix, iStim in enumerate(stimIx):\n",
    "    X[stimId[ix]-1, stimIx[ix]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot stimulus vector\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.plot(t, stimData);\n",
    "plt.xlim((0, np.max(t)));\n",
    "plt.xlabel('Time [s]');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# plot design matrix\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.plot(t, X.T);\n",
    "plt.xlim((0, np.max(t)));\n",
    "plt.xlabel('Time [s]');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# we approximate the shape of the typical calcium response by convolving the design matrix with a \n",
    "# canonical (double-exponential) calcium transient\n",
    "# to do this, we define a function using the key word 'def'\n",
    "# this function can later be evaluated with different inputs\n",
    "\n",
    "def convolveStimWithCalciumResponse(stim, t, tauOn, tauOff):\n",
    "    # canonical calcium indicator response characteristics\n",
    "    # tauOn ... onset time in s\n",
    "    # tauOff ... offset time in s\n",
    "    signal = (1-(np.exp(-t/tauOn)))*(np.exp(-(t/tauOff)));\n",
    "    \n",
    "    # convolve stimulus with the canonical calcium indicator response\n",
    "    stim_conv = np.convolve(stim, signal)\n",
    "    stim_conv = np.delete(stim_conv, range(len(stim),len(stim_conv)))\n",
    "    return stim_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Now we actually convolve the design matrix with the calcium response\n",
    "tauOn = 0.5 # in s\n",
    "tauOff = 5 # in s\n",
    "Xconv = np.zeros((nStims, nTimepoints), float)\n",
    "for iStim in range(nStims):\n",
    "    Xconv[iStim, :] = convolveStimWithCalciumResponse(X[iStim, :], t, tauOn, tauOff)\n",
    "# plot convolved stimulus matrix\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.plot(t, Xconv.T);\n",
    "plt.xlim((0, np.max(t)));\n",
    "plt.xlabel('Time [s]');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Now we are ready to create and fit the regression model\n",
    "from regression import LinearRegression\n",
    "algorithm = LinearRegression(fit_intercept=True, normalize=True)\n",
    "model,score = algorithm.fit_and_score(Xconv.T, series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Results of the regression analysis are provided as regression coefficients (betas) for each stimulus \n",
    "# and the overall goodness-of-fit of the model\n",
    "\n",
    "# extract betas as array and plot\n",
    "betas = model.betas.toarray()\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "# beta matrix image\n",
    "fig = plt.imshow(betas, cmap='gray', interpolation='nearest', \n",
    "           aspect=0.25, origin='lower', vmin=0, vmax=100)\n",
    "plt.xlabel('StimID')\n",
    "plt.ylabel('Neuron ID')\n",
    "plt.xticks([])\n",
    "plt.colorbar();\n",
    "plt.show()\n",
    "# plt.savefig('GLM_betaImage.tiff', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true,
      "layout": {}
     }
    }
   },
   "outputs": [],
   "source": [
    "# Plot goodness of model fit (R^2) for each Roi\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(range(nNeurons), score.toarray());\n",
    "plt.xlabel('Neuron ID');\n",
    "plt.ylabel('Model fit / R^2');\n",
    "plt.xlim((0, nNeurons));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the provided LinearRegression algorithm, we can also specify customized regression models. This approach allows us to use many of the algorithms available in the [scikit-learn](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use a Lasso linear model with iterative fitting\n",
    "from regression import CustomRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "algorithm_lcv = CustomRegression(LassoCV(normalize=True, fit_intercept=True, selection='random'))\n",
    "model_lcv, score_lcv = algorithm_lcv.fit_and_score(Xconv.T, series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract betas as array and plot\n",
    "betas_lcv = model_lcv.betas.toarray()\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "# beta matrix image\n",
    "fig = plt.imshow(betas_lcv, cmap='gray', interpolation='nearest', \n",
    "           aspect=0.25, origin='lower', vmin=0, vmax=100)\n",
    "plt.xlabel('StimID')\n",
    "plt.ylabel('Neuron ID')\n",
    "plt.xticks([])\n",
    "plt.colorbar();\n",
    "plt.show()\n",
    "# plt.savefig('GLM_betaImage.tiff', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot goodness of model fit (R^2) for each Roi\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(range(nNeurons), score_lcv.toarray());\n",
    "plt.xlabel('Neuron ID');\n",
    "plt.ylabel('Model fit / R^2');\n",
    "plt.xlim((0, nNeurons));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "urth": {
   "dashboard": {
    "cellMargin": 10,
    "defaultCellHeight": 20,
    "layout": "grid",
    "maxColumns": 12
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot widefield calcium imaging data\n",
    "This notebook demonstrates how to plot the data for a selected trial after preprocessing has been performed with the notebook Widefield_Preproc_Spark_Swift. The data (DFF and movie arrays) are read from the corresponding HDF5 files stored on Swift. The following graphics are generated: first frame and average of movie, mask used for processing, ROI locations, DFF traces for selected ROIs, movie of DFF array. Since we only process a single selected trial here, Spark is not required and the notebook runs entirely on the driver node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Python modules\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.animation as animation\n",
    "from __future__ import print_function\n",
    "import h5py\n",
    "import getpass\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# the notebook backend: 'local' or 'openstack'\n",
    "nbBackend = 'openstack'\n",
    "\n",
    "# add folder 'utils' to the Python path\n",
    "# this folder contains custom written code that is required for data import and analysis\n",
    "utils_dir = os.path.join(os.getcwd(), 'utils')\n",
    "sys.path.append(utils_dir)\n",
    "import SwiftStorageUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import custom-written modules\n",
    "import WidefieldDataUtils as wf\n",
    "import PickleUtils as pick\n",
    "import CalciumAnalysisUtils as calciumTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# swift file system\n",
    "swift_container = 'ariel' # specify name of container in Swift (do not use _ etc.)\n",
    "swift_provider = 'SparkTest' # in general, this should not change\n",
    "swift_basename = \"swift://\" + swift_container + \".\" + swift_provider + \"/\"\n",
    "\n",
    "# storage location of RDDs relative to swift_basename (from Widefield_Preproc_Spark_Swift notebook)\n",
    "output_folder_mov = 'mov_out'\n",
    "output_folder_dff = 'dff_out'\n",
    "\n",
    "# select file to be displayed\n",
    "selected_file = '20152310_092225_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OpenStack credentials for accessing Swift storage\n",
    "os_username = 'hluetc'\n",
    "os_tenant_name = 'helmchen.hifo.uzh'\n",
    "os_auth_url = 'https://cloud.s3it.uzh.ch:5000/v2.0'\n",
    "# provide OS password\n",
    "os_password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put all these params in a dict for later access\n",
    "file_params = dict()\n",
    "file_params['swift_container'] = swift_container\n",
    "file_params['swift_provider'] = swift_provider\n",
    "file_params['swift_basename'] = swift_basename\n",
    "file_params['os_username'] = os_username\n",
    "file_params['os_tenant_name'] = os_tenant_name\n",
    "file_params['os_auth_url'] = os_auth_url\n",
    "file_params['os_password'] = os_password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from HDF5 file\n",
    "This part loads the data from the HDF5 file stored on Swift. To do this, the file is first downloaded from Swift storage to a temporary folder. Then, we use standard Python libraries to read the HDF5 file. Finally, the temporary fodler is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getArrayFromH5(h5file, dataset_name):\n",
    "    with h5py.File(h5file,'r') as hf:\n",
    "        print('List of arrays in HDF5 file: ', hf.keys())\n",
    "        data = hf.get(dataset_name)\n",
    "        data = np.array(data)\n",
    "        print('Shape of the array %s: ' % (dataset_name), data.shape)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# local storage directory --> remember to delete afterwards\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "# file to download from Swift\n",
    "objects_to_download = [\n",
    "    '%s/%s.h5' % (output_folder_mov, selected_file),\n",
    "    '%s/%s.h5' % (output_folder_dff, selected_file)\n",
    "]\n",
    "\n",
    "# download options\n",
    "down_opts = {\n",
    "    'skip_identical': True,\n",
    "    'out_directory': temp_dir,\n",
    "}\n",
    "\n",
    "# download file to local directory\n",
    "from SwiftStorageUtils import downloadItems\n",
    "downloadItems(swift_container, objects_to_download, file_params, down_opts)\n",
    "\n",
    "# read file from local directory\n",
    "mov_file = '%s%s%s%s%s.h5' % (temp_dir, os.path.sep, output_folder_mov, os.path.sep, selected_file)\n",
    "dff_file = '%s%s%s%s%s.h5' % (temp_dir, os.path.sep, output_folder_dff, os.path.sep, selected_file)\n",
    "\n",
    "mov_data = getArrayFromH5(mov_file, 'mov')\n",
    "dff_data = getArrayFromH5(dff_file, 'dff')\n",
    "\n",
    "# delete temp dir\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run some checks and get the image dimensions and number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the mov and dff arrays must be of equal size, otherwise there is a problem\n",
    "assert np.array_equal(mov_data.shape, dff_data.shape)\n",
    "\n",
    "# get the image dimensions and number of timepoints\n",
    "dims_analysis = (mov_data.shape[0], mov_data.shape[1])\n",
    "timepoints = mov_data.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the time vector, define trial times and specify the files with ROI and trial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time vector and trial times\n",
    "sample_rate = 20.0 # Hz\n",
    "t = (np.array(range(timepoints)) / sample_rate) - 3.0\n",
    "\n",
    "t_stim = -1.9 # stimulus cue (auditory)\n",
    "t_textIn = 0 # texture in (i.e. stimulus onset)\n",
    "t_textOut = 2 # texture starting to move out (stimulus offset)\n",
    "t_response = 4.9 # response cue for licking (auditory)\n",
    "t_base = -2 # baseline end (for F0 calculation)\n",
    "\n",
    "# ROI definitions\n",
    "roi_file = 'rois_OCIA.mat'\n",
    "dims_roi = (256,256) # image dimensions on which coordinates in roi_file are based\n",
    "\n",
    "# File with trial indices\n",
    "trials_index_file = 'trials_ind.mat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display frames from movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display from selected file (frame 1, mean, DFF mask)\n",
    "print('File: %s' % (selected_file))\n",
    "xy = (mov_data.shape[0]/1.05, mov_data.shape[1] - (mov_data.shape[1]/1.1))\n",
    "f, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(mov_data[:,:,0], cmap='gray', interpolation='none')\n",
    "axes[0].annotate('Frame %1.0f' % 0, xy=xy, fontsize=14, color='yellow', horizontalalignment='right')\n",
    "axes[1].imshow(np.nanmean(mov_data, axis=2), cmap='gray', interpolation='none')\n",
    "axes[1].annotate('Mean', xy=xy, fontsize=14, color='yellow', horizontalalignment='right')\n",
    "# calculate mask\n",
    "dff_data_mean = np.mean(dff_data, axis=2)\n",
    "masked = np.nanmean(mov_data, axis=2)\n",
    "masked[np.isnan(dff_data_mean)] = np.nanmax(masked)\n",
    "axes[2].imshow(masked, cmap='gray', interpolation='none')\n",
    "axes[2].annotate('Mask', xy=xy, fontsize=14, color='black', horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Rois and trial indices\n",
    "The approach for importing mat-files from Swift storage is the same as for HDF5 files: first download files from Swift storage to a temporary folder. Then, we use custom-written code to read the mat-files. Finally, the temporary folder is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download and import Roi and trial index files\n",
    "objects_to_download = [\n",
    "    roi_file,\n",
    "    trials_index_file\n",
    "]\n",
    "# local storage directory --> remember to delete afterwards\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# download options\n",
    "down_opts = {\n",
    "    'skip_identical': True,\n",
    "    'out_directory': temp_dir,\n",
    "}\n",
    "\n",
    "from SwiftStorageUtils import downloadItems\n",
    "downloadItems(swift_container, objects_to_download, file_params, down_opts)\n",
    "\n",
    "trial_ind = wf.importTrialIndices('%s%strials_ind.mat' % (temp_dir, os.path.sep))\n",
    "\n",
    "# Specify ROIs to pull out\n",
    "roi_file = '%s%srois_OCIA.mat' % (temp_dir, os.path.sep)\n",
    "roi_dict = {'roi_S1BC': [], 'roi_A1': [], 'roi_EC': [], 'roi_M2': []}\n",
    "roi_dict = wf.importMatlabRois(roi_file, roi_dict, dims_roi, dims_analysis)\n",
    "\n",
    "# delete temp dir\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out the trial type of the currently selected file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrialType(selected_file, trial_ind):\n",
    "    \"\"\"\n",
    "    Return trial type of input file from trial_ind.\n",
    "    \"\"\"\n",
    "    # parse file name to get trial_no\n",
    "    p = re.compile('\\d{1,8}')\n",
    "    file_info = p.findall(selected_file)\n",
    "    trial_no = int(file_info[2])\n",
    "    # search trial_ind for trial_type\n",
    "    trial_type = [i for i in trial_ind if trial_no in trial_ind[i]]\n",
    "    if not len(trial_type):\n",
    "        return 'void'\n",
    "    else:\n",
    "        return trial_type[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trial_type = getTrialType(selected_file, trial_ind)\n",
    "print('%s Trial type: %s' % (selected_file, trial_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROI positions on average of all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sanity check: Plot position of Rois\n",
    "%matplotlib inline\n",
    "print('File: %s' % (selected_file))\n",
    "f, axes = plt.subplots(1, len(roi_dict), figsize=(20,5))\n",
    "for ix, roi in enumerate(roi_dict):\n",
    "    avg_img_roi =np.mean(mov_data, axis=2)\n",
    "    avg_img_roi[roi_dict[roi][0], roi_dict[roi][1]] = np.nan\n",
    "    axes[ix].imshow(avg_img_roi, cmap='gray', interpolation='none', vmin=100, vmax=25000)\n",
    "    axes[ix].annotate('%s' % (roi), xy=xy, fontsize=14, color='white', horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot DFF traces\n",
    "Now we can pull out and plot the dF/F traces for selected ROIs. For plotting we use the Bokeh interactive visualization library, which offers a number of nice features for plotting and interacting with plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Bokeh library\n",
    "from bokeh.plotting import Figure, show\n",
    "from bokeh.models import Range1d, CrosshairTool, HoverTool\n",
    "from bokeh.io import output_notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This has to be in a separate cell, otherwise it wont work.\n",
    "from bokeh import resources\n",
    "output_notebook(resources=resources.INLINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getHover():\n",
    "    \"\"\"Define and return hover tool for a plot\"\"\"\n",
    "    # Define hover tool\n",
    "    hover = HoverTool()\n",
    "    hover.tooltips = [\n",
    "        (\"index\", \"$index\"),\n",
    "        (\"(x,y)\", \"($x, $y)\"),\n",
    "        (\"fill color\", \"$color[hex, swatch]:fill_color\"),\n",
    "    ]\n",
    "    return hover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotTimeseries(p, t, y, legend):\n",
    "    \"\"\"\n",
    "    Plot a timeseries in Figure p using the Bokeh library\n",
    "    \n",
    "    Input arguments:\n",
    "    p ... Bokeh figure\n",
    "    t ... 1d time axis vector (numpy array)\n",
    "    y ... 2d data numpy array (number of traces x time)\n",
    "    \"\"\"\n",
    "    colors_list = ['red', 'green', 'blue', 'yellow', 'black']\n",
    "    p.add_tools(CrosshairTool(), getHover())\n",
    "    for i in range(y.shape[0]):\n",
    "        p.line(t, y[i, :], line_width=2, legend=legend[i], color=colors_list[i])\n",
    "    left, right = np.min(t), np.max(t)\n",
    "    p.set(x_range=Range1d(left, right))\n",
    "    show(p)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we loop through the ROIs in roi_dict, pull out the corresponding dFF traces and plot them. The resulting figure allows interactive zooming, scrolling and inspection of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roi_data_cat = np.array([]).reshape(0,200)\n",
    "legend = []\n",
    "for ix, i_roi in enumerate(roi_dict):\n",
    "    roi_xy = roi_dict[i_roi]\n",
    "    roi_data = np.nanmean(dff_data[roi_xy[0], roi_xy[1], :], axis=0)\n",
    "    roi_data_cat = np.concatenate((roi_data_cat, roi_data[:, np.newaxis].T), axis=0)\n",
    "    legend.append(i_roi)\n",
    "p = Figure(plot_width=800, plot_height=300, title=('dF/F Traces %s - %s' % (selected_file, trial_type)))    \n",
    "plotTimeseries(p, t, roi_data_cat, legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DFF movie\n",
    "Finally, we create a movie from the dFF array and save it under the folder animations on Swift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wf.saveMovie(dff_data, trial_type, '%s_dFF' % (selected_file), sample_rate, t, file_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: reading from Spark pickle file into RDD (do NOT use for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize Spark\n",
    "# specify the number of cores and the memory of the workers\n",
    "# each worker VM has 8 cores and 32 GB of memory\n",
    "# the status of the cluster (ie. how many workers are available) can be checked in the admin console:\n",
    "# https://cloud.s3it.uzh.ch/project/instances/\n",
    "# when changing these settings, keep in mind that other people might be using the cluster\n",
    "# returns the SparkContext object 'sc' which tells Spark how to access the cluster\n",
    "# from setupSpark import initSpark\n",
    "# sc = initSpark(nbBackend, max_cores=8, worker_memory='10G')\n",
    "\n",
    "# # provide OS credentials to the Hadoop configuration\n",
    "# sc._jsc.hadoopConfiguration().set('fs.swift.service.SparkTest.username', os_username)\n",
    "# sc._jsc.hadoopConfiguration().set('fs.swift.service.SparkTest.tenant', os_tenant_name)\n",
    "# sc._jsc.hadoopConfiguration().set('fs.swift.service.SparkTest.password', os_password)\n",
    "\n",
    "# # add Python files in 'utils' folder to the SparkContext \n",
    "# # this is required so that all files are available on all the cluster workers\n",
    "# for filename in os.listdir(utils_dir):\n",
    "#     if filename.endswith('.py'):\n",
    "#         sc.addPyFile(os.path.join(utils_dir, filename))\n",
    "\n",
    "# # load movie RDD\n",
    "# mov_rdd = sc.pickleFile('%s%s' % (file_params['swift_basename'], output_folder_mov))\n",
    "\n",
    "# # load DFF RDD\n",
    "# dff_rdd = sc.pickleFile('%s%s' % (file_params['swift_basename'], output_folder_dff))\n",
    "\n",
    "# # Collect data for selected file\n",
    "# mov_rdd = mov_rdd.filter(lambda (k,v): selected_file in k)\n",
    "# dff_rdd = dff_rdd.filter(lambda (k,v): selected_file in k)\n",
    "\n",
    "# # get selected movie (return key-value tuple)\n",
    "# selected_mov = mov_rdd.first()\n",
    "# mov_data = selected_mov[1]\n",
    "\n",
    "# # get DFF data for selected file\n",
    "# selected_dff = dff_rdd.first()\n",
    "# dff_data = selected_dff[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

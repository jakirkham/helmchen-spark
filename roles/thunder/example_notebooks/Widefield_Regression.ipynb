{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Python modules\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "from matplotlib import font_manager\n",
    "from __future__ import print_function\n",
    "import getpass\n",
    "import tempfile\n",
    "import shutil\n",
    "import h5py\n",
    "import re\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add folder 'utils' to the Python path\n",
    "# this folder contains custom written code that is required for data import and analysis\n",
    "utils_dir = os.path.join(os.getcwd(), 'utils')\n",
    "sys.path.append(utils_dir)\n",
    "\n",
    "import SwiftStorageUtils\n",
    "import WidefieldDataUtils as wf\n",
    "import CalciumAnalysisUtils as calciumTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File access parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# swift file system\n",
    "swift_container = 'ariel' # specify name of container in Swift (do not use _ etc.)\n",
    "swift_provider = 'SparkTest' # in general, this should not change\n",
    "swift_basename = \"swift://\" + swift_container + \".\" + swift_provider + \"/\"\n",
    "\n",
    "# storage location of dFF data (from Widefield_Preproc_Spark_Swift notebook)\n",
    "output_folder_dff = 'dff_out'\n",
    "\n",
    "# start of name for matching files\n",
    "filename_start = '20152310_' # all files with names starting like this will be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OpenStack credentials for accessing Swift storage\n",
    "os_username = 'hluetc'\n",
    "os_tenant_name = 'helmchen.hifo.uzh'\n",
    "os_auth_url = 'https://cloud.s3it.uzh.ch:5000/v2.0'\n",
    "# provide OS password\n",
    "os_password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put all these params in a dict for later access\n",
    "file_params = dict()\n",
    "file_params['swift_container'] = swift_container\n",
    "file_params['swift_provider'] = swift_provider\n",
    "file_params['swift_basename'] = swift_basename\n",
    "file_params['os_username'] = os_username\n",
    "file_params['os_tenant_name'] = os_tenant_name\n",
    "file_params['os_auth_url'] = os_auth_url\n",
    "file_params['os_password'] = os_password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import trial index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download file with trial indices\n",
    "trials_index_file = 'trials_ind.mat'\n",
    "\n",
    "# download and import trial index files\n",
    "objects_to_download = [\n",
    "    trials_index_file\n",
    "]\n",
    "# local storage directory --> remember to delete afterwards\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# download options\n",
    "down_opts = {\n",
    "    'skip_identical': True,\n",
    "    'out_directory': temp_dir,\n",
    "}\n",
    "\n",
    "from SwiftStorageUtils import downloadItems\n",
    "status = downloadItems(swift_container, objects_to_download, file_params, down_opts)\n",
    "\n",
    "if not status:\n",
    "    print('Could not download file. Is the password correct?')\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "trial_ind = wf.importTrialIndices('%s%strials_ind.mat' % (temp_dir, os.path.sep))\n",
    "\n",
    "# delete temp dir\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from SwiftStorageUtils import listItems\n",
    "object_list = listItems(swift_container, file_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objects_to_download = [n for n in object_list if n.startswith(output_folder_dff) and filename_start in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getArrayFromH5(h5file, dataset_name):\n",
    "    with h5py.File(h5file,'r') as hf:\n",
    "#         print('List of arrays in HDF5 file: ', hf.keys())\n",
    "        data = hf.get(dataset_name)\n",
    "        data = np.array(data)\n",
    "#         print('Shape of the array %s: ' % (dataset_name), data.shape)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from SwiftStorageUtils import downloadItems\n",
    "def downloadFromSwift(obj, file_params):\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    # download options\n",
    "    down_opts = {\n",
    "        'skip_identical': True,\n",
    "        'out_directory': temp_dir,\n",
    "    }\n",
    "    downloadItems(file_params['swift_container'], [obj], file_params, down_opts)\n",
    "    \n",
    "    local_file = '%s%s%s' % (temp_dir, os.path.sep, obj)\n",
    "#     print('Local file: ', local_file)\n",
    "    \n",
    "    data = getArrayFromH5(local_file, 'dff')\n",
    "    \n",
    "    # delete temp dir\n",
    "    shutil.rmtree(temp_dir)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download first file to get dimensions / timepoints\n",
    "dff_data = downloadFromSwift(objects_to_download[0], file_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimensions = (dff_data.shape[0], dff_data.shape[1])\n",
    "timepoints = dff_data.shape[2]\n",
    "\n",
    "# time vector\n",
    "sample_rate = 20.0 # Hz\n",
    "t = (np.array(range(timepoints)) / sample_rate) - 3.0\n",
    "\n",
    "t_stim = -1.9 # stimulus cue (auditory)\n",
    "t_textIn = 0 # texture in (i.e. stimulus onset)\n",
    "t_textOut = 2 # texture starting to move out (stimulus offset)\n",
    "t_response = 4.9 # response cue for licking (auditory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrialType(selected_file, trial_ind):\n",
    "    \"\"\"\n",
    "    Return trial type from of input file from trial_ind\n",
    "    \"\"\"\n",
    "    # parse file name to get trial_no\n",
    "    p = re.compile('\\d{1,8}')\n",
    "    file_info = p.findall(selected_file)\n",
    "    trial_no = int(file_info[2])\n",
    "    # search trial_ind for trial_type\n",
    "    trial_type = [i for i in trial_ind if trial_no in trial_ind[i]]\n",
    "    if not len(trial_type):\n",
    "        return 'void'\n",
    "    else:\n",
    "        return trial_type[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup design matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildDesignMatrix(trial_type):\n",
    "    # setup design matrix for one trial\n",
    "    # columns: cue_stim, tr_100_In, tr_1200_In, tr_100_Out, tr_1200_Out, response_100, response_1200 \n",
    "    # use 'dummy variables' to model the different trial conditions and phases\n",
    "    # note: the baseline is not modeled explicitely, but implicitely (absence of all other conditions)\n",
    "    if trial_type == 'tr_100':\n",
    "        design_matrix = np.array([\n",
    "                (0, 0, 0, 0, 0, 0, 0),\n",
    "                (1, 0, 0, 0, 0, 0, 0), \n",
    "                (0, 1, 0, 0, 0, 0, 0), \n",
    "                (0, 0, 0, 1, 0, 0, 0), \n",
    "                (0, 0, 0, 0, 0, 1, 0)\n",
    "            ])\n",
    "    elif trial_type == 'tr_1200':\n",
    "        design_matrix = np.array([\n",
    "                (0, 0, 0, 0, 0, 0, 0),\n",
    "                (1, 0, 0, 0, 0, 0, 0), \n",
    "                (0, 0, 1, 0, 0, 0, 0), \n",
    "                (0, 0, 0, 0, 1, 0, 0), \n",
    "                (0, 0, 0, 0, 0, 0, 1)\n",
    "            ])\n",
    "    return design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of model parameter IDs (for labeling)\n",
    "param_ids = [\n",
    "    'cue_stim', \n",
    "    'tr_100_In', \n",
    "    'tr_1200_In', \n",
    "    'tr_100_Out', \n",
    "    'tr_1200_Out', \n",
    "    'response_100', \n",
    "    'response_1200' \n",
    "]\n",
    "# setup design matrix X\n",
    "X = np.empty((0,len(param_ids)), bool)\n",
    "for i_file in objects_to_download:\n",
    "    trial_type = getTrialType(i_file, trial_ind)\n",
    "    if trial_type == 'void':\n",
    "        continue\n",
    "    X_trial = buildDesignMatrix(trial_type)\n",
    "    X = np.append(X, X_trial, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from setupSpark import initSpark\n",
    "# Initialize Spark\n",
    "# specify the number of cores and the memory of the workers\n",
    "# each worker VM has 8 cores and 32 GB of memory\n",
    "# the status of the cluster (ie. how many cores are available) can be checked in the Spark UI:\n",
    "# http://SparkMasterIP:8080/\n",
    "\n",
    "spark_instances = 1 # the number of workers to be used\n",
    "executor_cores = 2 # the number of cores to be used on each worker\n",
    "executor_memory = '2G' # the amount of memory to be used on each worker\n",
    "max_cores = 2 # the max. number of cores Spark is allowed to use overall\n",
    "\n",
    "# returns the SparkContext object 'sc' which tells Spark how to access the cluster\n",
    "sc = initSpark('local', spark_instances=spark_instances, executor_cores=executor_cores, \\\n",
    "               max_cores=max_cores, executor_memory=executor_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add Python files in 'utils' folder to the SparkContext \n",
    "# this is required so that all files are available on all the cluster workers\n",
    "for filename in os.listdir(utils_dir):\n",
    "    if filename.endswith('.py'):\n",
    "        sc.addPyFile(os.path.join(utils_dir, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data into Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stimDataFromMov(mov, t, t_stim, t_textIn, t_textOut, t_response):\n",
    "    '''\n",
    "    Extract stimulus data for a whole movie using matrix-based indexing. Return tuple with 1 2D matrix per condition.\n",
    "    '''\n",
    "    # get data for base, cue, stimulus, response\n",
    "    base_data = np.nanmean(mov[:,:,9:12], axis=2)\n",
    "    stim_cue_data = np.nanmax(mov[:,:,(t >= t_stim) & (t < t_stim+0.2)], axis=2)\n",
    "    textIn_data = np.nanmax(mov[:,:,(t >= t_textIn) & (t < t_textIn+1)], axis=2)\n",
    "    textOut_data = np.nanmax(mov[:,:,(t >= t_textOut-1) & (t < t_textOut)], axis=2)\n",
    "    response_data = np.nanmax(mov[:,:,(t >= t_response) & (t < t_response+1)], axis=2)\n",
    "    return (base_data, stim_cue_data, textIn_data, textOut_data, response_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStimDataFromFile(file_name, file_params, trial_ind, t, t_stim, t_textIn, t_textOut, t_response, dimensions):\n",
    "    dff_data = downloadFromSwift(file_name, file_params)\n",
    "    trial_type = getTrialType(file_name, trial_ind)\n",
    "    if trial_type == 'void':\n",
    "        return None\n",
    "    else:\n",
    "        stim_data = stimDataFromMov(dff_data, t, t_stim, t_textIn, t_textOut, t_response)\n",
    "        stim_data_out = np.zeros((len(stim_data), dimensions[0]*dimensions[1]))\n",
    "        for ix, i_stim in enumerate(stim_data):\n",
    "            stim_data_out[ix, :] = np.reshape(i_stim, (1, np.prod(dimensions)), order='C')\n",
    "        return stim_data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_rdd = sc.parallelize(objects_to_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stim_data_rdd = file_rdd.map(lambda x: \n",
    "                             getStimDataFromFile(x, file_params, trial_ind, t, t_stim, t_textIn, \n",
    "                                                 t_textOut, t_response, dimensions)).filter(lambda x: \n",
    "                                                                                            x is not None).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use flatMap to split up stim_data_rdd by pixel. One element per pixel / trial with 5 data points. Pixel index as key. Then use reduceByKey to join elements for the same pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stim_data_flat = stim_data_rdd.flatMap(lambda (arr): ([x for x in arr.T]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reps = stim_data_flat.count()/np.prod(dimensions)\n",
    "ix = range(np.prod(dimensions))\n",
    "key_list = ix * reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stim_data_flat = stim_data_flat.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assignKeyFromList(rdd_el, key_list):\n",
    "    rdd_content = rdd_el[0]\n",
    "    rdd_ix = rdd_el[1]\n",
    "    rdd_key = key_list[rdd_ix]\n",
    "    return (rdd_key, rdd_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stim_data_flat = stim_data_flat.map(lambda x: assignKeyFromList(x, key_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_by_pixel_rdd = stim_data_flat.reduceByKey(lambda a,b: np.vstack((a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replaceNanAndReshape(arr):\n",
    "    if np.all(np.isnan(arr[1])):\n",
    "        out = np.nan\n",
    "    else:\n",
    "        out = np.reshape(arr, (arr.size, 1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_by_pixel_rdd = response_by_pixel_rdd.mapValues(lambda x: replaceNanAndReshape(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def runLinearRegression(y, X, regr):\n",
    "    '''\n",
    "    Fit linear regression object (regr) with model (X) and response vector (y)\n",
    "    \n",
    "    Return tuple: (goodness-of-fit (r^2), coefficients (betas), intercept)\n",
    "    '''\n",
    "    betas = np.zeros(X.shape[1])\n",
    "    if np.any(np.isnan(y)):\n",
    "        rsq = np.nan\n",
    "        betas[:] = np.nan\n",
    "        intercept = np.nan\n",
    "    else:\n",
    "        # fit the model\n",
    "        regr.fit(X, y)\n",
    "        # coefficient of determination of prediction (R^2)\n",
    "        rsq = regr.score(X, y)\n",
    "        # coefficients\n",
    "        betas[:] = regr.coef_\n",
    "        # intercept\n",
    "        intercept = regr.intercept_\n",
    "    return (rsq, betas, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "results_rdd = response_by_pixel_rdd.mapValues(lambda y_pixel: runLinearRegression(y_pixel, X, regr)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keys = results_rdd.keys().collect()\n",
    "sort_ix = np.argsort(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot a histogram of R^2 (goodness-of-fit) values over all pixels\n",
    "rsq_all = np.array(results_rdd.values().map(lambda (rsq,beta,interc): rsq).collect())\n",
    "plt.hist(rsq_all[~np.isnan(rsq_all)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot an image of R^2 values\n",
    "rsq_img = np.reshape(rsq_all[sort_ix], dimensions, order='C')\n",
    "im = plt.imshow(rsq_img)\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot coefficient maps (for inspection)\n",
    "beta_all = np.array(results_rdd.values().map(lambda (rsq,beta,interc): beta).collect())\n",
    "vmin = 0\n",
    "vmax = 10\n",
    "fig, axes = plt.subplots(1, beta_all.shape[1], figsize=(30,10))\n",
    "for ix, row in enumerate(beta_all.T):\n",
    "    beta_img = np.reshape(row[sort_ix], dimensions, order='C')\n",
    "    im = axes[ix].imshow(beta_img, vmin=vmin, vmax=vmax)\n",
    "    axes[ix].set_title(param_ids[ix])\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.81, 0.38, 0.03, 0.25])\n",
    "text = cbar_ax.yaxis.label\n",
    "font = font_manager.FontProperties(family='times new roman', style='italic', size=16)\n",
    "text.set_font_properties(font)\n",
    "fig.colorbar(im, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot coefficient maps (for print, i.e. larger)\n",
    "beta_all = np.array(results_rdd.values().map(lambda (rsq,beta,interc): beta).collect())\n",
    "vmin = 0\n",
    "vmax = 10\n",
    "for ix, row in enumerate(beta_all.T):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    beta_img = np.reshape(row[sort_ix], dimensions, order='C')\n",
    "    im = plt.imshow(beta_img, vmin=vmin, vmax=vmax)\n",
    "#     axes[ix].set_title(param_ids[ix])\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.81, 0.38, 0.03, 0.25])\n",
    "text = cbar_ax.yaxis.label\n",
    "font = font_manager.FontProperties(family='times new roman', style='italic', size=16)\n",
    "text.set_font_properties(font)\n",
    "fig.colorbar(im, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old: Derive response_rdd from response matrix\n",
    "Not using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# get response data for all pixels\n",
    "# create a 2D response_matrix with responses in rows and pixels in columns\n",
    "# TODO: use Spark to make this more efficient (distribute files)\n",
    "response_matrix = np.zeros((X.shape[0], dimensions[0]*dimensions[1]))\n",
    "row = 0\n",
    "for i_file in objects_to_download:\n",
    "    dff_data = downloadFromSwift(i_file, file_params)\n",
    "    trial_type = getTrialType(i_file, trial_ind)\n",
    "    if trial_type == 'void':\n",
    "        continue\n",
    "    stim_data = stimDataFromMov(dff_data, t, t_stim, t_textIn, t_textOut, t_response)\n",
    "    for ix, i_stim in enumerate(stim_data):\n",
    "        response_matrix[row+ix, :] = np.reshape(i_stim, (1, dimensions[0]*dimensions[1]), order='C')\n",
    "    row += len(stim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('response_matrix', response_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_matrix = np.load('response_matrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getResponseData(ix, response_matrix):\n",
    "    response_data = response_matrix[:,ix]\n",
    "    if np.any(np.isnan(response_data)):\n",
    "        response_data = np.nan\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response_rdd = sc.parallelize(range(response_matrix.shape[1])).map(lambda x: (x, x))\n",
    "response_rdd = response_rdd.mapValues(lambda ix: getResponseData(ix, response_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dummy data to test RDD transform\n",
    "arr = np.array(([1,2,3,4,5,6], [10,20,30,40,50,60], [100,200,300,400,500,600]))\n",
    "lst = [arr, arr, arr, arr]\n",
    "\n",
    "# convert to RDD\n",
    "lst_rdd = sc.parallelize(lst)\n",
    "\n",
    "lst_rdd.count()\n",
    "\n",
    "lst_rdd.first().shape\n",
    "\n",
    "lst_rdd_flat = lst_rdd.flatMap(lambda arr: [x for x in arr.T])\n",
    "\n",
    "reps = lst_rdd_flat.count()/lst_rdd.first().shape[1]\n",
    "ix = range(lst_rdd.first().shape[1])\n",
    "key_list = ix * reps\n",
    "\n",
    "lst_rdd_flat = lst_rdd_flat.zipWithIndex()\n",
    "\n",
    "lst_rdd_flat = lst_rdd_flat.map(lambda x: assignKeyFromList(x, key_list))\n",
    "\n",
    "lst_rdd_flat.collect()\n",
    "\n",
    "lst_rdd_flat.reduceByKey(lambda a,b: np.vstack((a,b))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Local implementation (non-Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the model (X) to the response (y) for each pixel (mass-univariate approach)\n",
    "# TODO: use Spark to make this more efficient (distribute pixels)\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "r_sq_all = np.zeros((response_matrix.shape[1]))\n",
    "beta_all = np.zeros((X.shape[1], response_matrix.shape[1]))\n",
    "\n",
    "# fit for all pixels\n",
    "for ix, y_pixel in enumerate(response_matrix.T):\n",
    "    if np.any(np.isnan(y_pixel)):\n",
    "        r_sq_all[ix] = np.nan\n",
    "        beta_all[:, ix] = np.nan\n",
    "        continue\n",
    "    # fit the model\n",
    "    regr.fit(X, y_pixel)\n",
    "    # coefficient of determination of prediction (R^2)\n",
    "    r_sq_all[ix] = regr.score(X, y_pixel)\n",
    "    # coefficients\n",
    "    beta_all[:, ix] = regr.coef_\n",
    "    # intercept (this should be v. close to 0 as we selected the baseline frames above)\n",
    "    # regr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "# Beta images\n",
    "vmin = 0\n",
    "vmax = 10\n",
    "fig, axes = plt.subplots(1, beta_all.shape[0], figsize=(30,10))\n",
    "for ix, row in enumerate(beta_all):\n",
    "    beta_img = np.reshape(row, dimensions, order='C')\n",
    "    im = axes[ix].imshow(beta_img, vmin=vmin, vmax=vmax)\n",
    "    axes[ix].set_title(param_ids[ix])\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.81, 0.38, 0.03, 0.25])\n",
    "text = cbar_ax.yaxis.label\n",
    "font = font_manager.FontProperties(family='times new roman', style='italic', size=16)\n",
    "text.set_font_properties(font)\n",
    "fig.colorbar(im, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DFF image (as sanity check for orientation)\n",
    "plt.imshow(np.nanmean(dff_data, axis=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
